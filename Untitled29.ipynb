{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKATtNn_clRb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "try:\n",
        "    df1= pd.read_csv('/content/drive/My Drive/santander-customer-transaction-prediction/train.csv')\n",
        "    df2= pd.read_csv('/content/drive/My Drive/santander-customer-transaction-prediction/test.csv')\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}. Please check the file paths and ensure the files exist in your Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "df1.head()\n",
        "df2.head()\n",
        "df1.shape\n",
        "df2.shape\n",
        "\n",
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df1, title=\"Pandas Profiling Report\")\n",
        "profile.to_file(output_file = 'output1.html')\n",
        "\n",
        "from ydata_profiling import ProfileReport\n",
        "profile = ProfileReport(df2, title=\"Pandas Profiling Report2\")\n",
        "profile.to_file(output_file = 'output2.html')\n",
        "\n",
        "\n",
        "variable_cols_df1 = df1.columns[2:]\n",
        "variable_cols_df2 = df2.columns[1:]\n",
        "\n",
        "\n",
        "#EDA Analysis starts here .......\n",
        "# Ensure both lists of variable columns have the same length and correspond to the same variables\n",
        "# Assuming the variable columns are in the same order and named consistently\n",
        "variable_cols = [col for col in variable_cols_df1 if col in variable_cols_df2]\n",
        "\n",
        "\n",
        "# Determine the number of rows and columns for subplots\n",
        "n_cols_per_row = 4\n",
        "n_rows = (len(variable_cols) + n_cols_per_row - 1) // n_cols_per_row\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols_per_row, figsize=(20, n_rows * 5))\n",
        "fig.suptitle('Distribution Comparison of Variables in df1 and df2', y=1.02)\n",
        "\n",
        "# Flatten the axes array for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(variable_cols):\n",
        "    if i < len(axes): # Ensure we don't go out of bounds of the axes array\n",
        "        sns.histplot(df1[col], ax=axes[i], color='skyblue', label='df1', kde=True)\n",
        "        sns.histplot(df2[col], ax=axes[i], color='lightcoral', label='df2', kde=True)\n",
        "        axes[i].set_title(col)\n",
        "        axes[i].set_xlabel(col)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].legend()\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "df1_means = df1.iloc[:, 2:].mean()\n",
        "df2_means = df2.iloc[:, 1:].mean()\n",
        "\n",
        "# Plot using subplots\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.kdeplot(df1_means, ax=ax, label='df1', color='blue')\n",
        "sns.kdeplot(df2_means, ax=ax, label='df2', color='red')\n",
        "ax.set_title('Distribution of column means for df1 and df2')\n",
        "ax.set_xlabel('Mean values')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Compute row means:\n",
        "# For df1, start from the 3rd column (index 2)\n",
        "df1_row_means = df1.iloc[:, 2:].mean(axis=1)\n",
        "# For df2, start from the 2nd column (index 1)\n",
        "df2_row_means = df2.iloc[:, 1:].mean(axis=1)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.kdeplot(df1_row_means, label='df1', color='blue')\n",
        "sns.kdeplot(df2_row_means, label='df2', color='red')\n",
        "plt.title('Distribution of row means for df1 and df2')\n",
        "plt.xlabel('Row mean value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Column-wise min and max (skip ID columns)\n",
        "df1_col_min = df1.iloc[:, 2:].min()\n",
        "df2_col_min = df2.iloc[:, 1:].min()\n",
        "df1_col_max = df1.iloc[:, 2:].max()\n",
        "df2_col_max = df2.iloc[:, 1:].max()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.kdeplot(df1_col_min, label='df1', color='blue')\n",
        "sns.kdeplot(df2_col_min, label='df2', color='red')\n",
        "plt.title('Column-wise Min')\n",
        "plt.xlabel('Min value')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(df1_col_max, label='df1', color='blue')\n",
        "sns.kdeplot(df2_col_max, label='df2', color='red')\n",
        "plt.title('Column-wise Max')\n",
        "plt.xlabel('Max value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Row-wise min and max (skip ID columns)\n",
        "df1_row_min = df1.iloc[:, 2:].min(axis=1)\n",
        "df2_row_min = df2.iloc[:, 1:].min(axis=1)\n",
        "df1_row_max = df1.iloc[:, 2:].max(axis=1)\n",
        "df2_row_max = df2.iloc[:, 1:].max(axis=1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.kdeplot(df1_row_min, label='df1', color='blue')\n",
        "sns.kdeplot(df2_row_min, label='df2', color='red')\n",
        "plt.title('Row-wise Min')\n",
        "plt.xlabel('Min value')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(df1_row_max, label='df1', color='blue')\n",
        "sns.kdeplot(df2_row_max, label='df2', color='red')\n",
        "plt.title('Row-wise Max')\n",
        "plt.xlabel('Max value')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "df1_cols = df1.iloc[:, 2:]\n",
        "df2_cols = df2.iloc[:, 1:]\n",
        "\n",
        "# Calculate column-wise stats\n",
        "df1_skew_col = df1_cols.skew()\n",
        "df2_skew_col = df2_cols.skew()\n",
        "df1_std_col = df1_cols.std()\n",
        "df2_std_col = df2_cols.std()\n",
        "df1_kurt_col = df1_cols.kurtosis()\n",
        "df2_kurt_col = df2_cols.kurtosis()\n",
        "\n",
        "plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.kdeplot(df1_skew_col, label=\"df1\", color=\"blue\")\n",
        "sns.kdeplot(df2_skew_col, label=\"df2\", color=\"red\")\n",
        "plt.title(\"Column-wise Skewness\")\n",
        "plt.xlabel(\"Skewness\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.kdeplot(df1_std_col, label=\"df1\", color=\"blue\")\n",
        "sns.kdeplot(df2_std_col, label=\"df2\", color=\"red\")\n",
        "plt.title(\"Column-wise Std Dev\")\n",
        "plt.xlabel(\"Std Dev\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.kdeplot(df1_kurt_col, label=\"df1\", color=\"blue\")\n",
        "sns.kdeplot(df2_kurt_col, label=\"df2\", color=\"red\")\n",
        "plt.title(\"Column-wise Kurtosis\")\n",
        "plt.xlabel(\"Kurtosis\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Calculate row-wise stats\n",
        "df1_skew_row = df1_cols.skew(axis=1)\n",
        "df2_skew_row = df2_cols.skew(axis=1)\n",
        "df1_std_row = df1_cols.std(axis=1)\n",
        "df2_std_row = df2_cols.std(axis=1)\n",
        "df1_kurt_row = df1_cols.kurtosis(axis=1)\n",
        "df2_kurt_row = df2_cols.kurtosis(axis=1)\n",
        "\n",
        "plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.kdeplot(df1_skew_row, label=\"df1\", color=\"blue\")\n",
        "sns.kdeplot(df2_skew_row, label=\"df2\", color=\"red\")\n",
        "plt.title(\"Row-wise Skewness\")\n",
        "plt.xlabel(\"Skewness\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.kdeplot(df1_std_row, label=\"df1\", color=\"blue\")\n",
        "sns.kdeplot(df2_std_row, label=\"df2\", color=\"red\")\n",
        "plt.title(\"Row-wise Std Dev\")\n",
        "plt.xlabel(\"Std Dev\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.kdeplot(df1_kurt_row, label=\"df1\", color=\"blue\")\n",
        "sns.kdeplot(df2_kurt_row, label=\"df2\", color=\"red\")\n",
        "plt.title(\"Row-wise Kurtosis\")\n",
        "plt.xlabel(\"Kurtosis\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 1. Select feature columns and split by target ---\n",
        "features = [col for col in df1.columns if col not in ['ID_code', 'target']]\n",
        "df0_ = df1[df1['target'] == 0][features]\n",
        "df1_ = df1[df1['target'] == 1][features]\n",
        "\n",
        "# --- 2. Column-wise statistics (per feature, grouped by target) ---\n",
        "column_stats = {}\n",
        "for stat_name, func in [\n",
        "    ('mean', 'mean'),\n",
        "    ('min', 'min'),\n",
        "    ('max', 'max'),\n",
        "    ('std', 'std'),\n",
        "    ('skew', 'skew'),\n",
        "    ('kurt', 'kurtosis'),\n",
        "]:\n",
        "    column_stats[stat_name] = pd.DataFrame({\n",
        "        'target=0': getattr(df0_, func)(),\n",
        "        'target=1': getattr(df1_, func)(),\n",
        "    })\n",
        "\n",
        "\n",
        "# --- 3. Row-wise statistics (computed per row, grouped by target) ---\n",
        "row_stats = {}\n",
        "for stat_name, func in [\n",
        "    ('mean', 'mean'),\n",
        "    ('min', 'min'),\n",
        "    ('max', 'max'),\n",
        "    ('std', 'std'),\n",
        "    ('skew', 'skew'),\n",
        "    ('kurt', 'kurtosis'),\n",
        "]:\n",
        "    row_stats[stat_name] = {\n",
        "        'target=0': getattr(df0_, func)(axis=1),\n",
        "        'target=1': getattr(df1_, func)(axis=1),\n",
        "    }\n",
        "\n",
        "\n",
        "# Print column means\n",
        "print(\"Column means by target:\")\n",
        "print(column_stats['mean'])\n",
        "\n",
        "# Draw distribution of row min values split by target\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(row_stats['min']['target=0'], color='blue', kde=True, label='target=0')\n",
        "sns.histplot(row_stats['min']['target=1'], color='red', kde=True, label='target=1')\n",
        "plt.title(\"Distribution of Row Minimum by Target\")\n",
        "plt.xlabel(\"Row min\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# --- 1. Select feature columns and split by target ---\n",
        "features = [col for col in df1.columns if col not in ['ID_code', 'target']]\n",
        "df0_ = df1[df1['target'] == 0][features]\n",
        "df1_ = df1[df1['target'] == 1][features]\n",
        "\n",
        "# 2. Column-wise statistics\n",
        "column_stats = {}\n",
        "for stat_name, func in [\n",
        "    ('mean', 'mean'),\n",
        "    ('min', 'min'),\n",
        "    ('max', 'max'),\n",
        "    ('std', 'std'),\n",
        "    ('skew', 'skew'),\n",
        "    ('kurt', 'kurtosis'),\n",
        "]:\n",
        "    column_stats[stat_name] = pd.DataFrame({\n",
        "        'target=0': getattr(df0_, func)(),\n",
        "        'target=1': getattr(df1_, func)(),\n",
        "    })\n",
        "\n",
        "# 3. Row-wise statistics\n",
        "row_stats = {}\n",
        "for stat_name, func in [\n",
        "    ('mean', 'mean'),\n",
        "    ('min', 'min'),\n",
        "    ('max', 'max'),\n",
        "    ('std', 'std'),\n",
        "    ('skew', 'skew'),\n",
        "    ('kurt', 'kurtosis'),\n",
        "]:\n",
        "    row_stats[stat_name] = {\n",
        "        'target=0': getattr(df0_, func)(axis=1),\n",
        "        'target=1': getattr(df1_, func)(axis=1),\n",
        "    }\n",
        "\n",
        "\n",
        "# COLUMN-WISE PLOTS wrt target\n",
        "for stat in column_stats:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.histplot(column_stats[stat]['target=0'], kde=True, color='blue', label='target=0')\n",
        "    sns.histplot(column_stats[stat]['target=1'], kde=True, color='red', label='target=1')\n",
        "    plt.title(f\"Column-wise {stat.capitalize()} by Target\")\n",
        "    plt.xlabel(stat.capitalize())\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# ROW-WISE PLOTS wrt Target\n",
        "for stat in row_stats:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.histplot(row_stats[stat]['target=0'], kde=True, color='blue', label='target=0')\n",
        "    sns.histplot(row_stats[stat]['target=1'], kde=True, color='red', label='target=1')\n",
        "    plt.title(f\"Row-wise {stat.capitalize()} by Target\")\n",
        "    plt.xlabel(stat.capitalize())\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "corrs = df1.drop('ID_code', axis=1).corr()['target'].drop(['target'], errors='ignore').sort_values(key=abs, ascending=False)\n",
        "print(\"Correlation of all columns to target:\")\n",
        "print(corrs)\n",
        "\n",
        "train1 = df1.copy()\n",
        "test1= df2.copy()\n",
        "\n",
        "#new features\n",
        "\n",
        "# Select the features (use your structure: adjust column indices as needed)\n",
        "features_df1 = train1.columns.values[2:202]   # Typically skips ID/target in tabular competitions\n",
        "features_df2 = test1.columns.values[1:202]\n",
        "\n",
        "for df, idx in zip([train1, test1], [features_df1, features_df2]):\n",
        "    df['sum'] = df[idx].sum(axis=1)\n",
        "    df['min'] = df[idx].min(axis=1)\n",
        "    df['max'] = df[idx].max(axis=1)\n",
        "    df['mean'] = df[idx].mean(axis=1)\n",
        "    df['std'] = df[idx].std(axis=1)\n",
        "    df['skew'] = df[idx].skew(axis=1)\n",
        "    df['kurt'] = df[idx].kurtosis(axis=1)\n",
        "    df['med'] = df[idx].median(axis=1)\n",
        "\n",
        "\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#PREPARE DATA\n",
        "X = train1.drop(columns=['ID_code', 'target'])  # Exclude ID/target\n",
        "y = train1['target']\n",
        "\n",
        "#PARAMETER GRID FOR TUNING\n",
        "param_grid = {\n",
        "    'num_leaves': [31, 50, 70, 100],\n",
        "    'learning_rate': [0.01, 0.03, 0.05],\n",
        "    'max_depth': [7, 10, 15, 20],\n",
        "    'min_data_in_leaf': [100, 300, 500, 1000],\n",
        "    'feature_fraction': [0.8, 0.9, 1.0],\n",
        "    'bagging_fraction': [0.4,0.8, 0.9, 1.0],\n",
        "    'bagging_freq': [1, 2, 5],\n",
        "    'lambda_l1': [0, 0.1, 0.5, 1.0],\n",
        "    'lambda_l2': [0, 0.1, 0.5, 1.0],\n",
        "    'n_estimators': [100, 300, 600]\n",
        "}\n",
        "\n",
        "# CV & SEARCH SETUP\n",
        "clf = lgb.LGBMClassifier(objective='binary', boosting_type='gbdt', random_state=42, n_jobs=-1)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    clf,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=30,  # Increase for more thorough search\n",
        "    scoring='roc_auc',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    refit=True\n",
        ")\n",
        "\n",
        "#  FIT THE SEARCH\n",
        "search.fit(X, y)\n",
        "\n",
        "print(\"Best parameters:\", search.best_params_)\n",
        "print(\"Best cross-validated ROC-AUC:\", search.best_score_)\n",
        "\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Prepare your data\n",
        "X = train1.drop(columns=['ID_code', 'target'])\n",
        "y = train1['target']\n",
        "\n",
        "def objective(trial):\n",
        "    param = {\n",
        "        'objective': 'binary',\n",
        "        'boosting_type': 'gbdt',\n",
        "        'metric': 'auc',\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'num_leaves': trial.suggest_categorical('num_leaves', [31, 50, 70, 100]),\n",
        "        'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.03, 0.05]),\n",
        "        'max_depth': trial.suggest_categorical('max_depth', [7, 10, 15, 20]),\n",
        "        'min_data_in_leaf': trial.suggest_categorical('min_data_in_leaf', [100, 300, 500, 1000]),\n",
        "        'feature_fraction': trial.suggest_categorical('feature_fraction', [0.8, 0.9, 1.0]),\n",
        "        'bagging_fraction': trial.suggest_categorical('bagging_fraction', [0.4, 0.8, 0.9, 1.0]),\n",
        "        'bagging_freq': trial.suggest_categorical('bagging_freq', [1, 2, 5]),\n",
        "        'lambda_l1': trial.suggest_categorical('lambda_l1', [0, 0.1, 0.5, 1.0]),\n",
        "        'lambda_l2': trial.suggest_categorical('lambda_l2', [0, 0.1, 0.5, 1.0]),\n",
        "        'n_estimators': trial.suggest_categorical('n_estimators', [100, 300, 600])\n",
        "    }\n",
        "\n",
        "    # Stratified split to maintain target distribution\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,\n",
        "                                                          stratify=y, random_state=42)\n",
        "    model = lgb.LGBMClassifier(**param)\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_metric='auc',\n",
        "        callbacks=[lgb.early_stopping(stopping_rounds=20, verbose=False)] )\n",
        "    preds = model.predict_proba(X_valid)[:, 1]\n",
        "    auc = roc_auc_score(y_valid, preds)\n",
        "    return auc\n",
        "\n",
        "# Create and run Optuna study to maximize ROC-AUC\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
        "\n",
        "print(\"Best ROC-AUC:\", study.best_value)\n",
        "print(\"Best hyperparameters:\", study.best_trial.params)\n",
        "\n",
        "# Use training data with features (X) and target (y). Adjust column dropping as needed.\n",
        "X1 = train1.drop(columns=['ID_code', 'target'])\n",
        "y1 = train1['target']\n",
        "\n",
        "\n",
        "model = lgb.LGBMClassifier(\n",
        "    objective='binary',\n",
        "    boosting_type='gbdt',\n",
        "    num_leaves=50,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=20,\n",
        "    min_data_in_leaf=100,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.9,\n",
        "    bagging_freq=1,\n",
        "    lambda_l1=1.0,\n",
        "    lambda_l2=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    n_estimators=600\n",
        ")\n",
        "model.fit(X1, y1, eval_metric='auc')\n",
        "\n",
        "X_test = test1.drop(columns=['ID_code'])\n",
        "# Predict probabilities\n",
        "# model should be your trained LightGBM model\n",
        "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'ID_code': test1['ID_code'],\n",
        "    'target': y_test_pred_proba\n",
        "})\n",
        "\n",
        "#  Save submission\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file saved as 'submission.csv'\")\n",
        "\n",
        "importances = model.feature_importances_   # default: 'split'\n",
        "features = X1.columns\n",
        "importance_df = pd.DataFrame({'feature': features, 'importance': importances})\n",
        "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
        "\n",
        "\n",
        "# Select top N features (change N to 30 or 50 as desired)\n",
        "N = 30\n",
        "top_features = importance_df.sort_values(by='importance', ascending=False).head(N)['feature'].tolist()\n",
        "\n",
        "# Prepare new training data with only top N features\n",
        "X_top = train1[top_features]\n",
        "y = train1['target']\n",
        "\n",
        "# Train new LightGBM model (model2).\n",
        "model2 = lgb.LGBMClassifier(\n",
        "    objective='binary',\n",
        "    boosting_type='gbdt',\n",
        "    num_leaves=50,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=20, # Corrected max_depth as -20 is not a valid value\n",
        "    min_data_in_leaf=100,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.9,\n",
        "    bagging_freq=1,\n",
        "    lambda_l1=1.0,\n",
        "    lambda_l2=1.0,\n",
        "    random_state=42,\n",
        "    n_jobs=-1, # Added missing comma\n",
        "    n_estimators=600\n",
        ")\n",
        "model2.fit(X_top, y, eval_metric='auc')\n",
        "\n",
        "\n",
        "#  For prediction on test data (test1), use the same top features\n",
        "X_test_top = test1[top_features]\n",
        "test_preds = model2.predict_proba(X_test_top)[:, 1]\n",
        "submission2 = pd.DataFrame({'ID_code': test1['ID_code'], 'target': test_preds})\n",
        "submission2.to_csv('submission2.csv', index=False)\n",
        "\n",
        "print('model2 trained and submission.csv saved!')\n"
      ]
    }
  ]
}